import time
from core.logger import (
    logger, 
    log_sync_start, 
    log_sync_step, 
    log_sync_error, 
    log_sync_complete
)
from database.gsheet_manager import GSheetManager
from database.table_config import TABLES
from core.date_utils import looks_like_date_column, normalize_date_fields


class SyncBatchError(RuntimeError):
    """
    TÃ¼m tablo senkronizasyonunda birden fazla tablonun hata almasÄ± durumunu
    yapÄ±landÄ±rÄ±lmÄ±ÅŸ olarak taÅŸÄ±r.
    """

    def __init__(self, failures, total_tables=0, successful_tables=0):
        self.failures = failures or []
        self.total_tables = total_tables
        self.successful_tables = successful_tables
        failed_tables = [f.get("table", "?") for f in self.failures]
        super().__init__(f"Åžu tablolarda sync hatasÄ±: {', '.join(failed_tables)}")

    def to_ui_messages(self, max_tables=3):
        fail_count = len(self.failures)
        short_msg = f"{fail_count} tabloda hata"

        listed = [f.get("table", "?") for f in self.failures[:max_tables]]
        detail_msg = f"BaÅŸarÄ±sÄ±z tablolar: {', '.join(listed)}"
        if fail_count > max_tables:
            detail_msg += f" ve {fail_count - max_tables} tablo daha"

        return short_msg, detail_msg

    def to_event(self):
        return {
            "event": "SYNC_BATCH_FAILED",
            "total_tables": self.total_tables,
            "successful_tables": self.successful_tables,
            "failed_tables": len(self.failures),
            "failures": self.failures,
        }


class SyncService:
    """
    Senkronizasyon servisi.

    Her tablo iÃ§in akÄ±ÅŸ:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. Google Sheets'i TEK SEFER oku (read_all)
    2. Local dirty kayÄ±tlarÄ± topla
    3. PUSH: dirty kayÄ±tlarÄ± toplu gÃ¶nder (batch_update + batch_append)
    4. PULL: remote'ta olup local'de olmayanlarÄ± toplu ekle
    5. PULL: remote'taki gÃ¼ncellemeleri local'e yansÄ±t (clean kayÄ±tlar iÃ§in)
    6. Bir sonraki tabloya geÃ§

    API Ã§aÄŸrÄ± sayÄ±sÄ±:
    ESKÄ° â†’ tablo baÅŸÄ±na: 1 + (dirty Ã— 3) = onlarca istek
    YENÄ° â†’ tablo baÅŸÄ±na: 1 okuma + 1-2 yazma = 2-3 istek
    """

    def __init__(self, db, registry):
        self.db = db
        self.registry = registry
        self.gsheet = GSheetManager()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def sync_all(self):
        """
        TÃ¼m senkronize edilebilir tablolarÄ± sÄ±rayla iÅŸler.
        """
        syncable = [
            (name, cfg) for name, cfg in TABLES.items()
            if cfg.get("sync", True) and cfg.get("pk") is not None
        ]

        total = len(syncable)
        success = 0
        failures = []

        logger.info(f"Toplam {total} tablo senkronize edilecek")

        for i, (table_name, cfg) in enumerate(syncable, 1):
            try:
                logger.info(f"[{i}/{total}] {table_name} sync baÅŸladÄ±")
                log_sync_start(table_name)
                
                self.sync_table(table_name)
                
                success += 1
                logger.info(f"[{i}/{total}] {table_name} sync baÅŸarÄ±lÄ± âœ“")
                
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                failure = {
                    "event": "SYNC_TABLE_FAILED",
                    "table": table_name,
                    "step": "sync_table",
                    "error_type": error_type,
                    "error_msg": error_msg[:200],
                    "table_index": i,
                    "table_total": total,
                }
                 
                logger.error(f"[{i}/{total}] {table_name} sync hatasÄ±: {error_type}")
                log_sync_error(table_name, "sync_table", e)
                 
                failures.append(failure)
                 
                # Bir tablo hata alÄ±rsa diÄŸerlerine devam et
                continue

        # Ã–zet log
        logger.info("=" * 60)
        logger.info(f"SYNC Ã–ZETÄ°: {success}/{total} tablo baÅŸarÄ±lÄ±")
        if failures:
            logger.error(f"BaÅŸarÄ±sÄ±z tablolar: {len(failures)}")
            for fail in failures:
                logger.error(
                    f"  - {fail['table']}: {fail['error_type']} - {fail['error_msg']}"
                )
        logger.info("=" * 60)

        if failures:
            raise SyncBatchError(
                failures=failures,
                total_tables=total,
                successful_tables=success,
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def sync_table(self, table_name: str):
        """
        Tek tablo senkronizasyonu â€” optimize edilmiÅŸ akÄ±ÅŸ.
        Composite PK (list) ve tekli PK (string) destekler.
        
        ðŸ”§ FIX: Google Sheets'teki gÃ¼ncellemeler artÄ±k local'e yansÄ±yor!
        """
        cfg = TABLES[table_name]

        # â”€â”€ Pull-only tablolar (Sabitler, Tatiller) â”€â”€
        if cfg.get("sync_mode") == "pull_only":
            logger.info(f"  {table_name} pull_only modda Ã§alÄ±ÅŸÄ±yor")
            log_sync_step(table_name, "pull_only_mode")
            self._pull_replace(table_name, cfg)
            return
        
        repo = self.registry.get(table_name)
        cfg = TABLES[table_name]
        pk = cfg["pk"]  # string veya list

        # PK'yÄ± her zaman list olarak tut
        pk_cols = pk if isinstance(pk, list) else [pk]

        def make_key(data):
            """Dict'ten composite key string Ã¼retir."""
            return "|".join(str(data.get(col, "")).strip() for col in pk_cols)

        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # 1ï¸âƒ£  Google Sheets'i TEK SEFER oku
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log_sync_step(table_name, "read_remote")
            remote_rows, pk_index, ws = self.gsheet.read_all(table_name)
            log_sync_step(table_name, "read_remote_complete", len(remote_rows))

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # 2ï¸âƒ£  PUSH: Local â†’ Google Sheets
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log_sync_step(table_name, "check_dirty")
            dirty_rows = repo.get_dirty()
            logger.info(f"  Local dirty: {len(dirty_rows)}")

            to_update = []
            to_append = []

            for row in dirty_rows:
                key = make_key(row)
                if key in pk_index:
                    to_update.append(row)
                else:
                    to_append.append(row)

            if to_update:
                log_sync_step(table_name, "push_update", len(to_update))
                self.gsheet.batch_update(table_name, ws, pk_index, to_update)
                logger.info(f"  PUSH gÃ¼ncelleme: {len(to_update)}")

            if to_append:
                log_sync_step(table_name, "push_append", len(to_append))
                self.gsheet.batch_append(table_name, ws, to_append)
                logger.info(f"  PUSH yeni ekleme: {len(to_append)}")

            # Dirty â†’ clean
            just_pushed_keys = set()
            for row in dirty_rows:
                pk_val = {col: row.get(col) for col in pk_cols} if len(pk_cols) > 1 else row.get(pk_cols[0])
                repo.mark_clean(pk_val)
                just_pushed_keys.add(make_key(row))  # PULL'da stale remote ile ezilmesin

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # 3ï¸âƒ£  PULL: Google Sheets â†’ Local
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log_sync_step(table_name, "pull_remote")
            new_count = 0
            updated_count = 0

            for remote in remote_rows:
                key = make_key(remote)
                if not key or key == "|".join([""] * len(pk_cols)):
                    continue

                # Az Ã¶nce push edilmiÅŸ kayÄ±t: remote henÃ¼z gÃ¼ncel deÄŸil, atla
                if key in just_pushed_keys:
                    continue

                pk_val = {col: remote.get(col) for col in pk_cols} if len(pk_cols) > 1 else remote.get(pk_cols[0])
                local = repo.get_by_id(pk_val)

                if not local:
                    # Yeni kayÄ±t â†’ ekle
                    remote["sync_status"] = "clean"
                    repo.insert(remote)
                    new_count += 1
                else:
                    # ðŸ”§ FIX: Mevcut kayÄ±t var
                    # Local'de dirty deÄŸilse (yani kullanÄ±cÄ± deÄŸiÅŸtirmemiÅŸse),
                    # Google Sheets'teki gÃ¼ncellemeleri al
                    local_status = local.get("sync_status", "").strip()
                    
                    if local_status != "dirty":
                        # Remote'taki verilerle local'i gÃ¼ncelle
                        # (sync_status'u clean olarak koru)
                        remote["sync_status"] = "clean"
                        
                        # Sadece deÄŸiÅŸen alanlarÄ± gÃ¼ncelle
                        has_changes = False
                        for col in cfg["columns"]:
                            if col in ["sync_status", "updated_at"]:
                                continue
                            remote_val = str(remote.get(col, "")).strip()
                            local_val = str(local.get(col, "")).strip()
                            if remote_val != local_val:
                                has_changes = True
                                break
                        
                        if has_changes:
                            repo.insert(remote)  # INSERT OR REPLACE
                            updated_count += 1
                    # else: Local dirty â†’ kullanÄ±cÄ± deÄŸiÅŸtirmiÅŸ, dokunma

            if new_count:
                log_sync_step(table_name, "pull_new", new_count)
                logger.info(f"  PULL yeni kayÄ±t: {new_count}")
            
            if updated_count:
                log_sync_step(table_name, "pull_update", updated_count)
                logger.info(f"  PULL gÃ¼ncelleme: {updated_count}")

            # Ä°statistiklerle tamamlama logu
            stats = {
                'pushed': len(to_update) + len(to_append),
                'pulled': new_count + updated_count
            }
            log_sync_complete(table_name, stats)
            logger.info(f"  {table_name} sync tamamlandÄ± âœ“")
            
        except Exception as e:
            log_sync_error(table_name, "sync_table", e)
            raise  # HatayÄ± yukarÄ± ilet

    def _pull_replace(self, table_name, cfg):
        """
        Pull-only modda Ã§alÄ±ÅŸan tablolar iÃ§in Ã¶zel sync mantÄ±ÄŸÄ±.

        AkÄ±ÅŸ:
        1. Google Sheets'ten tÃ¼m kayÄ±tlarÄ± oku
        2. SatÄ±rlarÄ± doÄŸrula (boÅŸ PK, bilinmeyen kolon adÄ± vb.)
        3. Local tabloyu tamamen temizle
        4. INSERT OR REPLACE ile tÃ¼m kayÄ±tlarÄ± yaz
           (Sheets'te yinelenen PK varsa son deÄŸer kazanÄ±r)

        KullanÄ±m: Sabitler, Tatiller gibi sadece merkezi yÃ¶netilen tablolar iÃ§in
        """
        columns = cfg["columns"]
        pk = cfg["pk"]
        date_fields = cfg.get("date_fields") or [c for c in columns if looks_like_date_column(c)]
        # Composite PK desteÄŸi: string ise listeye Ã§evir
        pk_cols = pk if isinstance(pk, list) else [pk]

        try:
            log_sync_step(table_name, "pull_only_start")

            # â”€â”€ 1. Google Sheets'i oku â”€â”€
            from database.google import get_worksheet
            ws = get_worksheet(table_name)

            if not ws:
                logger.warning(f"  {table_name} worksheet bulunamadÄ±, atlanÄ±yor")
                return

            records = ws.get_all_records()
            log_sync_step(table_name, "pull_only_read", len(records))
            logger.info(f"  Google Sheets'ten {len(records)} kayÄ±t okundu")

            # â”€â”€ 2. BoÅŸ PK filtresi + aynÄ± tarihe dÃ¼ÅŸen tatilleri birleÅŸtir â”€â”€
            #
            # Ã–rnek: 23.04.2023 hem "Ramazan BayramÄ± 3.gÃ¼n" hem
            # "Ulusal Egemenlik ve Ã‡ocuk BayramÄ±" olabilir.
            # Tarih PRIMARY KEY olduÄŸu iÃ§in Ã§akÄ±ÅŸma yaÅŸanÄ±r.
            # Ã‡Ã¶zÃ¼m: aynÄ± tarihe ait isimleri " / " ile birleÅŸtirip tek kayÄ±t yap.
            #
            # ResmiTatil dÄ±ÅŸÄ±ndaki kolonlar (varsa) son satÄ±rÄ±n deÄŸerini alÄ±r.

            skipped_rows = []          # boÅŸ PK nedeniyle atlanan satÄ±rlar
            merged: dict = {}          # {tarih_key: row_dict}  (birleÅŸtirilmiÅŸ)
            merge_log: dict = {}       # {tarih_key: [isim1, isim2, ...]}

            MERGE_COL = "ResmiTatil"   # BirleÅŸtirilecek metin kolonu

            for i, row in enumerate(records, start=2):  # start=2: baÅŸlÄ±k satÄ±rÄ± 1
                row = normalize_date_fields(row, date_fields)
                pk_values = [str(row.get(col, "")).strip() for col in pk_cols]

                # BoÅŸ PK â†’ atla
                if any(v == "" for v in pk_values):
                    reason = f"BoÅŸ PK ({', '.join(pk_cols)}={pk_values})"
                    skipped_rows.append({"sheet_row": i, "reason": reason})
                    logger.warning(
                        f"  [{table_name}] SatÄ±r #{i} atlandÄ± â€” {reason} | "
                        f"Veri: { {c: row.get(c) for c in columns} }"
                    )
                    continue

                key = "|".join(pk_values)

                if key not in merged:
                    # Ä°lk kez gÃ¶rÃ¼len tarih: kaydÄ± olduÄŸu gibi al
                    merged[key] = {c: str(row.get(c, "")).strip() for c in columns}
                    merge_log[key] = [merged[key].get(MERGE_COL, "")]
                else:
                    # AynÄ± tarih tekrar geldi: sadece MERGE_COL'u birleÅŸtir,
                    # diÄŸer kolonlarÄ± son satÄ±rÄ±n deÄŸeriyle gÃ¼ncelle
                    yeni_isim = str(row.get(MERGE_COL, "")).strip()
                    if yeni_isim and yeni_isim not in merge_log[key]:
                        merge_log[key].append(yeni_isim)
                        merged[key][MERGE_COL] = " / ".join(merge_log[key])
                    # DiÄŸer kolonlarÄ± gÃ¼ncelle (PK ve MERGE_COL hariÃ§)
                    for c in columns:
                        if c not in pk_cols and c != MERGE_COL:
                            merged[key][c] = str(row.get(c, "")).strip()

            # BirleÅŸtirme Ã¶zeti logla
            merged_dates = [k for k, v in merge_log.items() if len(v) > 1]
            if merged_dates:
                logger.info(
                    f"  [{table_name}] AynÄ± gÃ¼ne dÃ¼ÅŸen {len(merged_dates)} tatil "
                    f"birleÅŸtirildi:"
                )
                for key in merged_dates:
                    logger.info(
                        f"    {key.replace('|', ' + ')} â†’ "
                        f"\"{merged[key].get(MERGE_COL)}\""
                    )

            if skipped_rows:
                logger.error(
                    f"  [{table_name}] {len(skipped_rows)} satÄ±r boÅŸ PK nedeniyle "
                    f"atlandÄ± â€” Google Sheets'te dÃ¼zeltilmesi gerekiyor!"
                )

            valid_records = list(merged.values())

            # â”€â”€ 3. Local tabloyu temizle â”€â”€
            self.db.execute(f"DELETE FROM {table_name}")
            logger.info(f"  Local {table_name} tablosu temizlendi")

            # â”€â”€ 4. INSERT ile kayÄ±tlarÄ± yaz â”€â”€
            # BirleÅŸtirme sonrasÄ± artÄ±k duplicate PK kalmaz,
            # yine de OR REPLACE bÄ±rakÄ±yoruz ek gÃ¼vence olarak.
            inserted = 0
            failed_rows = []
            cols_str = ", ".join(columns)
            placeholders = ", ".join(["?"] * len(columns))
            sql = f"INSERT OR REPLACE INTO {table_name} ({cols_str}) VALUES ({placeholders})"

            for row in valid_records:
                values = [row.get(col, "") for col in columns]
                try:
                    self.db.execute(sql, values)
                    inserted += 1
                except Exception as row_error:
                    row_preview = {c: row.get(c) for c in columns}
                    failed_rows.append({"error": str(row_error), "data": row_preview})
                    logger.error(
                        f"  [{table_name}] INSERT hatasÄ±: "
                        f"{type(row_error).__name__}: {row_error} | Veri: {row_preview}"
                    )
                    continue

            # â”€â”€ 5. Ã–zet rapor â”€â”€
            total_skipped = len(skipped_rows) + len(failed_rows)
            log_sync_step(table_name, "pull_only_complete", inserted)
            logger.info(
                f"  {table_name} pull_only tamamlandÄ±: "
                f"{inserted} kayÄ±t eklendi "
                f"({len(records)} Sheets satÄ±rÄ± â†’ {len(valid_records)} benzersiz kayÄ±t"
                + (f", {total_skipped} atlandÄ±" if total_skipped else "")
                + ") âœ“"
            )

            stats = {'pushed': 0, 'pulled': inserted}
            log_sync_complete(table_name, stats)

        except Exception as e:
            log_sync_error(table_name, "pull_only", e)
            raise
